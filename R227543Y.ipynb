{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhAiKTyz+dyrbCyALFupJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JOE101-max/R227543Y_BYNADGE-JAKARASI-DEEPLEARNING/blob/main/R227543Y.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZIMBABWE HOUSE PRICE PREDICTION: ROBUST LATE FUSION (20 MODEL BENCHMARK)\n",
        "# Full script: includes DenseNet fix, MAPE, per-model CSV export, device fixes\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# PyTorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Install timm if missing\n",
        "try:\n",
        "    import timm\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"timm\", \"-q\"])\n",
        "    import timm\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# 1. SETUP & CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    print(f\" GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\" WARNING: NO GPU DETECTED. Running on CPU.\")\n",
        "\n",
        "# (Colab drive mount attempt - harmless if not Colab)\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# PATHS - update these if needed\n",
        "CSV_PATH = '/content/drive/MyDrive/Zimbabwe_housing_data.csv'\n",
        "IMAGE_FOLDER = '/content/drive/MyDrive/images/'\n",
        "\n",
        "# HYPERPARAMETERS\n",
        "BATCH_SIZE = 32\n",
        "TOTAL_EPOCHS = 20\n",
        "WARMUP_EPOCHS = 5\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "TABULAR_FEATURES = ['bedrooms', 'bathrooms', 'land_area_sqm']\n",
        "LOCATION_COL = 'location'\n",
        "TOP_N_LOCATIONS = 12\n",
        "\n",
        "MODELS_REQ_299 = ['Inception-V3 (2015)', 'Inception-ResNet-V2 (2016)', 'InceptionV4 (2016)']\n",
        "\n",
        "FINAL_TABULAR_DIM = 0\n",
        "TARGET_MEAN = 0.0\n",
        "TARGET_STD = 1.0\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# UTIL: safe model name -> filename\n",
        "# -----------------------------------------------------------------------------\n",
        "def safe_name(s: str) -> str:\n",
        "    return s.replace(' ', '_').replace('/', '_').replace(',', '').replace(\"'\", \"\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# METRICS: MAPE\n",
        "# -----------------------------------------------------------------------------\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    eps = 1e-8\n",
        "    # Avoid division by zero: use y_true + eps in denominator\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + eps))) * 100.0\n"
      ],
      "metadata": {
        "id": "KXnkBVgBt481"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 2. DATA PIPELINE\n",
        "# -----------------------------------------------------------------------------\n",
        "def load_data(csv_path):\n",
        "    global FINAL_TABULAR_DIM, TARGET_MEAN, TARGET_STD\n",
        "\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"CSV not found at: {csv_path}\")\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    required = ['price', 'image_filenames'] + TABULAR_FEATURES + [LOCATION_COL]\n",
        "    missing_required = [c for c in required if c not in df.columns]\n",
        "    if missing_required:\n",
        "        raise ValueError(f\"Missing required columns: {missing_required}\")\n",
        "\n",
        "    df = df.dropna(subset=required)\n",
        "    df = df[df['price'].astype(float) > 2000]\n",
        "    df['image_filenames'] = df['image_filenames'].astype(str)\n",
        "\n",
        "    # Target log-price\n",
        "    df['log_price'] = np.log1p(df['price'].astype(float))\n",
        "\n",
        "    # Target scaling\n",
        "    TARGET_MEAN = df['log_price'].mean()\n",
        "    TARGET_STD = df['log_price'].std() if df['log_price'].std() > 0 else 1.0\n",
        "\n",
        "    # Tabular normalization (z-score)\n",
        "    for col in TABULAR_FEATURES:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)\n",
        "        m = df[col].mean()\n",
        "        s = df[col].std() if df[col].std() > 0 else 1.0\n",
        "        df[col] = (df[col] - m) / (s + 1e-9)\n",
        "\n",
        "    # One-hot top locations\n",
        "    top_locs = df[LOCATION_COL].value_counts().nlargest(TOP_N_LOCATIONS).index\n",
        "    for loc in top_locs:\n",
        "        safe_col = f'loc_{str(loc).strip().replace(\" \", \"_\")}'\n",
        "        df[safe_col] = (df[LOCATION_COL] == loc).astype(int)\n",
        "\n",
        "    loc_cols = [c for c in df.columns if c.startswith('loc_')]\n",
        "    final_cols = TABULAR_FEATURES + loc_cols\n",
        "    FINAL_TABULAR_DIM = len(final_cols)\n",
        "\n",
        "    print(f\"✅ Data Loaded: {len(df)} samples\")\n",
        "    print(f\"✅ Target (log-price) mean={TARGET_MEAN:.4f}, std={TARGET_STD:.4f}\")\n",
        "    print(f\"✅ Final tabular dim: {FINAL_TABULAR_DIM}\")\n",
        "\n",
        "    return df.reset_index(drop=True), final_cols\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Dataset\n",
        "# -----------------------------------------------------------------------------\n",
        "class LateFusionDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, feature_cols, transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.feature_cols = feature_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _open_image(self, fname):\n",
        "        p = os.path.join(self.root_dir, fname)\n",
        "        if os.path.exists(p):\n",
        "            try:\n",
        "                return Image.open(p).convert('RGB')\n",
        "            except Exception:\n",
        "                return None\n",
        "        # try absolute path\n",
        "        if os.path.exists(fname):\n",
        "            try:\n",
        "                return Image.open(fname).convert('RGB')\n",
        "            except Exception:\n",
        "                return None\n",
        "        return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_fname = row['image_filenames']\n",
        "        img = self._open_image(img_fname)\n",
        "        if img is None:\n",
        "            img = Image.new('RGB', (299, 299), color='black')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        tab_vals = row[self.feature_cols].values.astype(np.float32) if len(self.feature_cols) > 0 else np.zeros(0, dtype=np.float32)\n",
        "\n",
        "        raw_log = float(row['log_price'])\n",
        "        scaled_target = (raw_log - TARGET_MEAN) / (TARGET_STD + 1e-9)\n",
        "\n",
        "        return img, torch.tensor(tab_vals, dtype=torch.float32), torch.tensor(scaled_target, dtype=torch.float32)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Transforms\n",
        "# -----------------------------------------------------------------------------\n",
        "def get_transforms(size=224):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "nCmYc2lAuVDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 3. LATE FUSION MODEL\n",
        "# -----------------------------------------------------------------------------\n",
        "class LateFusionModel(nn.Module):\n",
        "    def __init__(self, cnn_backbone, tabular_input_dim):\n",
        "        super().__init__()\n",
        "        self.cnn = cnn_backbone\n",
        "        # turn off aux logits if present\n",
        "        if hasattr(self.cnn, 'aux_logits'):\n",
        "            try:\n",
        "                self.cnn.aux_logits = False\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # robust detection of cnn output size; handle DenseNet classifier single Linear\n",
        "        cnn_out = 0\n",
        "        try:\n",
        "            if hasattr(self.cnn, 'num_features') and getattr(self.cnn, 'num_features') is not None and getattr(self.cnn, 'num_features') > 0:\n",
        "                cnn_out = self.cnn.num_features\n",
        "\n",
        "            # classifier attribute (DenseNet: Linear OR Sequential)\n",
        "            if cnn_out == 0 and hasattr(self.cnn, 'classifier'):\n",
        "                clf = self.cnn.classifier\n",
        "                if isinstance(clf, nn.Linear):\n",
        "                    cnn_out = clf.in_features\n",
        "                    self.cnn.classifier = nn.Identity()\n",
        "                elif isinstance(clf, nn.Sequential) and len(clf) > 0:\n",
        "                    last = clf[-1]\n",
        "                    if hasattr(last, 'in_features'):\n",
        "                        cnn_out = last.in_features\n",
        "                    # remove final layer\n",
        "                    try:\n",
        "                        self.cnn.classifier = nn.Sequential(*list(clf.children())[:-1])\n",
        "                    except Exception:\n",
        "                        self.cnn.classifier = nn.Identity()\n",
        "\n",
        "            # torchvision style fc\n",
        "            if cnn_out == 0 and hasattr(self.cnn, 'fc') and hasattr(self.cnn.fc, 'in_features'):\n",
        "                cnn_out = self.cnn.fc.in_features\n",
        "                try:\n",
        "                    self.cnn.fc = nn.Identity()\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            # fallback: run a dummy forward\n",
        "            if cnn_out == 0:\n",
        "                self.cnn.eval()\n",
        "                with torch.no_grad():\n",
        "                    dummy = torch.zeros(1, 3, 299, 299).to(DEVICE) if DEVICE.type == 'cuda' else torch.zeros(1,3,299,299)\n",
        "                    out = self.cnn(dummy)\n",
        "                    if isinstance(out, tuple):\n",
        "                        out = out[0]\n",
        "                    if out.dim() > 2:\n",
        "                        out = torch.flatten(out, 1)\n",
        "                    cnn_out = out.shape[1]\n",
        "        except Exception:\n",
        "            cnn_out = 1000\n",
        "\n",
        "        self.img_projector = nn.Sequential(\n",
        "            nn.Linear(cnn_out, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        self.tabular_mlp = nn.Sequential(\n",
        "            nn.Linear(tabular_input_dim if tabular_input_dim > 0 else 1, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fusion_head = nn.Sequential(\n",
        "            nn.Linear(128 + 32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, tab):\n",
        "        x_img = self.cnn(img)\n",
        "        if isinstance(x_img, tuple):\n",
        "            x_img = x_img[0]\n",
        "        if x_img.dim() > 2:\n",
        "            x_img = torch.flatten(x_img, 1)\n",
        "        x_img = self.img_projector(x_img)\n",
        "\n",
        "        if tab.shape[1] == 0:\n",
        "            tab = torch.zeros((tab.shape[0], 1), device=tab.device)\n",
        "        x_tab = self.tabular_mlp(tab)\n",
        "\n",
        "        combined = torch.cat((x_img, x_tab), dim=1)\n",
        "        out = self.fusion_head(combined)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "qI9fqWLnubGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 4. BACKBONE FACTORY (with device-safe transfer)\n",
        "# -----------------------------------------------------------------------------\n",
        "def get_backbone(model_name):\n",
        "    \"\"\"Return pretrained backbone and move it to DEVICE immediately to avoid dtype mismatch.\"\"\"\n",
        "    mapping = {\n",
        "        'AlexNet (2012)': ('alexnet', 'torchvision'),\n",
        "        'VGG (2014)': ('vgg11', 'torchvision'),\n",
        "        'GoogLeNet / Inception-V1 (2014)': ('googlenet', 'torchvision'),\n",
        "        'Inception-V3 (2015)': ('inception_v3', 'torchvision'),\n",
        "        'ResNet (2016)': ('resnet50', 'torchvision'),\n",
        "        'DenseNet (2017)': ('densenet121', 'torchvision'),\n",
        "        'MobileNet V2 (2018)': ('mobilenet_v2', 'torchvision'),\n",
        "        'NiN (2013)': ('nin', 'timm'),\n",
        "        'ZNet': ('efficientnet_b0', 'timm'),\n",
        "        'InceptionV4 (2016)': ('inception_v4', 'timm'),\n",
        "        'Inception-ResNet-V2 (2016)': ('inception_resnet_v2', 'timm'),\n",
        "        'Xception (2017)': ('xception', 'timm'),\n",
        "        'WideResNet (2016)': ('wide_resnet50_2', 'timm'),\n",
        "        'HRNet V2 (2020)': ('hrnet_w18', 'timm'),\n",
        "        'Squeeze and Excitation Networks': ('seresnet50', 'timm'),\n",
        "        'Competitive Squeeze and Excitation Network': ('ecaresnet50d', 'timm'),\n",
        "        'Residual Attention Neural Network': ('resnest50d', 'timm'),\n",
        "        'Highway': ('resnet18', 'torchvision'),\n",
        "        'FractalNet': ('resnet18', 'torchvision'),\n",
        "        'Capsulenet': ('vgg11', 'torchvision'),\n",
        "    }\n",
        "\n",
        "    if model_name not in mapping:\n",
        "        print(f\"Skipping {model_name}: mapping missing.\")\n",
        "        return None\n",
        "\n",
        "    name, source = mapping[model_name]\n",
        "    try:\n",
        "        if source == 'torchvision':\n",
        "            # handle common torchvision names\n",
        "            if name == 'inception_v3':\n",
        "                model = models.inception_v3(weights='DEFAULT')\n",
        "            elif name == 'alexnet':\n",
        "                model = models.alexnet(weights='DEFAULT')\n",
        "            elif name == 'vgg11':\n",
        "                model = models.vgg11(weights='DEFAULT')\n",
        "            elif name == 'googlenet':\n",
        "                model = models.googlenet(weights='DEFAULT')\n",
        "            elif name == 'resnet50':\n",
        "                model = models.resnet50(weights='DEFAULT')\n",
        "            elif name == 'densenet121':\n",
        "                model = models.densenet121(weights='DEFAULT')\n",
        "            elif name == 'mobilenet_v2':\n",
        "                model = models.mobilenet_v2(weights='DEFAULT')\n",
        "            elif name == 'resnet18':\n",
        "                model = models.resnet18(weights='DEFAULT')\n",
        "            else:\n",
        "                # fallback to timm\n",
        "                model = timm.create_model(name, pretrained=True, num_classes=0)\n",
        "        else:\n",
        "            model = timm.create_model(name, pretrained=True, num_classes=0)\n",
        "\n",
        "        # Move model to device to avoid dtype mismatch issues\n",
        "        model = model.to(DEVICE)\n",
        "\n",
        "        # disable aux logits if present\n",
        "        if hasattr(model, 'aux_logits'):\n",
        "            try:\n",
        "                model.aux_logits = False\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to load backbone for {model_name}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "3dgIifh7upHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# 5. EXECUTION ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "def run_benchmark():\n",
        "    df, feature_cols = load_data(CSV_PATH)\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    models_to_run = [\n",
        "        'AlexNet (2012)', 'VGG (2014)', 'GoogLeNet / Inception-V1 (2014)',\n",
        "        'Inception-V3 (2015)', 'ResNet (2016)', 'DenseNet (2017)',\n",
        "        'MobileNet V2 (2018)', 'NiN (2013)', 'ZNet', 'InceptionV4 (2016)',\n",
        "        'Inception-ResNet-V2 (2016)', 'Xception (2017)', 'WideResNet (2016)',\n",
        "        'HRNet V2 (2020)', 'Squeeze and Excitation Networks',\n",
        "        'Competitive Squeeze and Excitation Network',\n",
        "        'Highway', 'FractalNet', 'Residual Attention Neural Network',\n",
        "        'Capsulenet'\n",
        "    ]\n",
        "\n",
        "    leaderboard = []\n",
        "\n",
        "    for model_name in models_to_run:\n",
        "        print(f\"\\n MODEL: {model_name}\")\n",
        "\n",
        "        img_size = 299 if model_name in MODELS_REQ_299 else 224\n",
        "\n",
        "        train_ds = LateFusionDataset(train_df, IMAGE_FOLDER, feature_cols, get_transforms(img_size))\n",
        "        val_ds = LateFusionDataset(val_df, IMAGE_FOLDER, feature_cols, get_transforms(img_size))\n",
        "\n",
        "        # data loader: use pin_memory when using CUDA for faster host->device copies\n",
        "        pin = True if DEVICE.type == 'cuda' else False\n",
        "        num_workers = 4 if DEVICE.type == 'cuda' else 0\n",
        "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=pin)\n",
        "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=pin)\n",
        "\n",
        "        backbone = get_backbone(model_name)\n",
        "        if backbone is None:\n",
        "            leaderboard.append({'Model': model_name, 'R2': np.nan, 'MAE': np.nan, 'MAPE': np.nan})\n",
        "            continue\n",
        "\n",
        "        # Build model using backbone already moved to DEVICE -> ensure LateFusionModel itself on DEVICE\n",
        "        model = LateFusionModel(backbone, tabular_input_dim=len(feature_cols)).to(DEVICE)\n",
        "\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
        "        use_amp = DEVICE.type == 'cuda'\n",
        "        scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
        "\n",
        "        start_t = time.time()\n",
        "\n",
        "        for epoch in range(TOTAL_EPOCHS):\n",
        "            model.train()\n",
        "            is_warmup = epoch < WARMUP_EPOCHS\n",
        "\n",
        "            # Freeze/unfreeze cnn params during warmup\n",
        "            for param in model.cnn.parameters():\n",
        "                param.requires_grad = not is_warmup\n",
        "\n",
        "            phase = \"WARMUP\" if is_warmup else \"FINE-TUNE\"\n",
        "\n",
        "            loop = tqdm(train_loader, desc=f\"Ep {epoch+1}/{TOTAL_EPOCHS} [{phase}]\", leave=False)\n",
        "            for imgs, tabs, lbls in loop:\n",
        "                imgs = imgs.to(DEVICE, non_blocking=pin)\n",
        "                tabs = tabs.to(DEVICE, non_blocking=pin)\n",
        "                lbls = lbls.to(DEVICE, non_blocking=pin).unsqueeze(1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                if use_amp:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        preds = model(imgs, tabs)\n",
        "                        loss = criterion(preds, lbls)\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    preds = model(imgs, tabs)\n",
        "                    loss = criterion(preds, lbls)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "        # ---------------- EVALUATION ----------------\n",
        "        model.eval()\n",
        "        scaled_actuals = []\n",
        "        scaled_preds = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, tabs, lbls in val_loader:\n",
        "                imgs = imgs.to(DEVICE, non_blocking=pin)\n",
        "                tabs = tabs.to(DEVICE, non_blocking=pin)\n",
        "                out = model(imgs, tabs)\n",
        "                scaled_preds.extend(out.cpu().numpy().flatten().tolist())\n",
        "                scaled_actuals.extend(lbls.numpy().flatten().tolist())\n",
        "\n",
        "        # Inverse scale (log domain)\n",
        "        log_actual = (np.array(scaled_actuals) * TARGET_STD) + TARGET_MEAN\n",
        "        log_pred = (np.array(scaled_preds) * TARGET_STD) + TARGET_MEAN\n",
        "\n",
        "        true_usd = np.expm1(log_actual)\n",
        "        pred_usd = np.expm1(log_pred)\n",
        "\n",
        "        # Metrics\n",
        "        try:\n",
        "            r2 = r2_score(true_usd, pred_usd)\n",
        "        except Exception:\n",
        "            r2 = float('nan')\n",
        "        try:\n",
        "            mae = mean_absolute_error(true_usd, pred_usd)\n",
        "        except Exception:\n",
        "            mae = float('nan')\n",
        "        try:\n",
        "            mape = mean_absolute_percentage_error(true_usd, pred_usd)\n",
        "        except Exception:\n",
        "            mape = float('nan')\n",
        "\n",
        "        print(f\"    Time: {time.time() - start_t:.1f}s\")\n",
        "        print(f\"    R²: {r2:.4f}\")\n",
        "        print(f\"    MAE: ${mae:,.0f}\")\n",
        "        print(f\"    MAPE: {mape:.2f}%\")\n",
        "\n",
        "        leaderboard.append({'Model': model_name, 'R2': r2, 'MAE': mae, 'MAPE': mape})\n",
        "\n",
        "        # ---------------- Save predictions CSV ----------------\n",
        "        try:\n",
        "            df_pred = pd.DataFrame({\n",
        "                'True_USD': true_usd,\n",
        "                'Predicted_USD': pred_usd\n",
        "            })\n",
        "            df_pred['Difference'] = df_pred['Predicted_USD'] - df_pred['True_USD']\n",
        "            csv_filename = f\"{safe_name(model_name)}_predictions.csv\"\n",
        "            df_pred.to_csv(csv_filename, index=False)\n",
        "            print(f\"    Predictions CSV saved: {csv_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"    Failed to save predictions CSV for {model_name}: {e}\")\n",
        "\n",
        "        # ---------------- PLOT + SMALL TABLE ----------------\n",
        "        try:\n",
        "            fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "            lim = min(len(true_usd), 500)  # plot up to 500 points\n",
        "            ax[0].scatter(true_usd[:lim], pred_usd[:lim], alpha=0.5, color='purple')\n",
        "            mn = min(true_usd[:lim].min(), pred_usd[:lim].min())\n",
        "            mx = max(true_usd[:lim].max(), pred_usd[:lim].max())\n",
        "            ax[0].plot([mn, mx], [mn, mx], 'r--')\n",
        "            ax[0].set_xlabel('Actual Price (USD)')\n",
        "            ax[0].set_ylabel('Predicted Price (USD)')\n",
        "            ax[0].set_title(f'{model_name} Results (R2={r2:.3f})')\n",
        "\n",
        "            table_rows = [[f\"${x:,.0f}\", f\"${y:,.0f}\"] for x, y in zip(true_usd[:5], pred_usd[:5])]\n",
        "            ax[1].axis('off')\n",
        "            ax[1].table(cellText=table_rows, colLabels=['Real', 'Predicted'], loc='center')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"    Plotting error for {model_name}: {e}\")\n",
        "\n",
        "        # cleanup\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Final leaderboard\n",
        "    final_df = pd.DataFrame(leaderboard).sort_values(by='R2', ascending=False)\n",
        "    final_df['MAE'] = final_df['MAE'].apply(lambda x: f\"${x:,.0f}\" if pd.notna(x) else \"N/A\")\n",
        "    final_df['MAPE'] = final_df['MAPE'].apply(lambda x: f\"{x:.2f}%\" if pd.notna(x) else \"N/A\")\n",
        "    print(\"\\n FINAL RANKING\")\n",
        "    print(final_df.reset_index(drop=True))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_benchmark()\n"
      ],
      "metadata": {
        "id": "0drIzGxXuwyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BYNADGE J JAKARASI\n",
        "\n",
        "Multimodal Price Prediction\n",
        "\n",
        "This project benchmarked a Late Fusion Multimodal Architecture for property price prediction, combining tabular data (MLP) and visual data (CNN).\n",
        "\n",
        "Key Approach\n",
        "\n",
        "Architecture: Utilized a Late Fusion strategy where tabular and image branches independently predicted prices, with the final output being the average of the two predictions.\n",
        "\n",
        "Missing Data: Applied a masking mechanism to handle missing images, allowing the model to rely solely on tabular data when visual data was unavailable.\n",
        "\n",
        "Training Robustness: Used log-scaling for the target price and the MSE loss function to stabilize training, given the extreme variance in property prices.\n",
        "\n",
        "Benchmarking: Evaluated twenty different CNN backbones, including Inception-V3, WideResNet, ResNet, VGG, MobileNet, and others.\n",
        "\n",
        "Results & Interpretation\n",
        "\n",
        "Best Model: Inception-V3 (2015) achieved the highest R² among all tested models.\n",
        "\n",
        "R²: 0.189\n",
        "\n",
        "MAE: $278,685\n",
        "\n",
        "MAPE: 102.96%\n",
        "\n",
        "Most models struggled to achieve positive R² values, highlighting the difficulty of predicting absolute property prices due to extreme variance and outliers in the dataset. Some models (e.g., AlexNet, VGG, Capsulenet) even produced negative R², indicating poor fit.\n",
        "\n",
        "Leaderboard Insight: Although models like Squeeze and Excitation Networks and Inception-ResNet-V2 were competitive in terms of MAE, none reliably captured the variance of the dataset, showing the inherent challenge of multimodal price prediction in this context.\n",
        "\n",
        "Next Steps\n",
        "Future work will focus on:\n",
        "\n",
        "Fine-tuning the top CNN backbones like Inception-V3 to improve predictive power.\n",
        "\n",
        "Experimenting with Early or Mid Fusion architectures to allow deeper interaction between tabular and visual features.\n",
        "\n",
        "Exploring data transformation techniques or quantile-based target scaling to reduce the impact of extreme outliers."
      ],
      "metadata": {
        "id": "eDdlEg--85h8"
      }
    }
  ]
}